<!DOCTYPE html>
<html lang="en-us">
  
  <script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    processEscapes: true
  }
});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Anatomy of Catastrophic Forgetting - Hidden Representations and Task Semantics &middot; Papers I Read
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="https://shagunsodhani.com/papers-I-read/public/css/poole.css">
  <link rel="stylesheet" href="https://shagunsodhani.com/papers-I-read/public/css/syntax.css">
  <link rel="stylesheet" href="https://shagunsodhani.com/papers-I-read/public/css/lanyon.css">
  <link rel="stylesheet" href="https://shagunsodhani.com/papers-I-read/public/css/style.css">
  <link rel="stylesheet" href="https://shagunsodhani.com/papers-I-read/public/font-awesome-4.7.0/css/font-awesome.css">

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://shagunsodhani.com/papers-I-read/public/apple-touch-icon-precomposed.png">
  <link rel="shortcut icon" href="https://shagunsodhani.com/papers-I-read/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>

  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-68140113-4"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-68140113-4');
</script>


  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <p>I am trying a new initiative - <i>A Paper A Week</i>. This blog will hold all the notes and summaries.</p>
  </div>

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item" href="https://shagunsodhani.com/papers-I-read/">Home</a>

    

    
    
      
        
      
    
      
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://shagunsodhani.com/papers-I-read/archieve">Archive</a>
        
      
    
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://shagunsodhani.com/papers-I-read/tags">Tags</a>
        
      
    

    <!-- <a class="sidebar-nav-item" href="https://github.com/shagunsodhani/papers-I-read/archive/v1.0.0.zip">Download</a> -->
    <a class="sidebar-nav-item" href="https://github.com/shagunsodhani/papers-I-read">GitHub project</a>
    <a class="sidebar-nav-item" href="https://shagunsodhani.com/papers-I-read/atom.xml">Feed</a>
    <!-- <span class="sidebar-nav-item">Currently v1.0.0</span> -->
  </nav>

  <div class="sidebar-item">
    <p>
      &copy; 2024. All rights reserved.
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="https://shagunsodhani.com/papers-I-read/" title="Home">Papers I Read</a>
            <small>Notes and Summaries</small>
          </h3>
        </div>
      </div>

      <div class="container content">
        <div class="post">
  <h1 class="post-title">Anatomy of Catastrophic Forgetting - Hidden Representations and Task Semantics</h1>
  <p class="entry-tags"><a href="https://shagunsodhani.com/papers-I-read/tags.html#2020" title="Pages tagged 2020" rel="tag">2020</a> &bull; <a href="https://shagunsodhani.com/papers-I-read/tags.html#Catastrophic+Forgetting" title="Pages tagged Catastrophic Forgetting" rel="tag">Catastrophic Forgetting</a> &bull; <a href="https://shagunsodhani.com/papers-I-read/tags.html#Continual+Learning" title="Pages tagged Continual Learning" rel="tag">Continual Learning</a> &bull; <a href="https://shagunsodhani.com/papers-I-read/tags.html#ICLR+2021" title="Pages tagged ICLR 2021" rel="tag">ICLR 2021</a> &bull; <a href="https://shagunsodhani.com/papers-I-read/tags.html#Lifelong+Learning" title="Pages tagged Lifelong Learning" rel="tag">Lifelong Learning</a> &bull; <a href="https://shagunsodhani.com/papers-I-read/tags.html#Replay+Buffer" title="Pages tagged Replay Buffer" rel="tag">Replay Buffer</a> &bull; <a href="https://shagunsodhani.com/papers-I-read/tags.html#Representation+Analysis" title="Pages tagged Representation Analysis" rel="tag">Representation Analysis</a> &bull; <a href="https://shagunsodhani.com/papers-I-read/tags.html#AI" title="Pages tagged AI" rel="tag">AI</a> &bull; <a href="https://shagunsodhani.com/papers-I-read/tags.html#CL" title="Pages tagged CL" rel="tag">CL</a> &bull; <a href="https://shagunsodhani.com/papers-I-read/tags.html#ICLR" title="Pages tagged ICLR" rel="tag">ICLR</a> &bull; <a href="https://shagunsodhani.com/papers-I-read/tags.html#LL" title="Pages tagged LL" rel="tag">LL</a></p>
  <span class="post-date">22 Feb 2021</span>
  <h2 id="introduction">Introduction</h2>

<ul>
  <li>
    <p>The paper studies the effect of catastrophic forgetting on representations in neural networks.</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2007.07400">Link to the paper</a></p>
  </li>
</ul>

<h2 id="setup">Setup</h2>

<ul>
  <li>
    <p>Techniques:</p>

    <ul>
      <li>
        <p>Representational Similarity Measures</p>
      </li>
      <li>
        <p>Layer Freezing</p>
      </li>
      <li>
        <p>Layer Reset</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Datasets</p>

    <ul>
      <li>
        <p>Split CIFAR-10</p>

        <ul>
          <li>
            <p>CIFAR-10 dataset is split into <em>m</em> (=2) tasks, where each task is a <em>n</em> way classification task.</p>
          </li>
          <li>
            <p>The underlying network has a shared trunk with <em>m</em> heads, one head per task.</p>
          </li>
        </ul>
      </li>
      <li>
        <p>Split CIFAR-100 Distribution Shift</p>

        <ul>
          <li>Each task requires distinguishing between <em>n</em> CIFAR-100 <em>superclasses</em> with training/test data corresponding to a <em>subset</em> of constituent classes.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>Network Architecture</p>

    <ul>
      <li>VGG, ResNet and DenseNet</li>
    </ul>
  </li>
</ul>

<h2 id="questions">Questions</h2>

<ul>
  <li>
    <p>Are all representations (throughout the network) equally responsible for forgetting?</p>

    <ul>
      <li>
        <p><em>Higher</em> layer (layers closer to the output) are the primary source of catastrophic forgetting.</p>
      </li>
      <li>
        <p><a href="https://arxiv.org/abs/1905.00414">Central Kernel Alignment (CKA)</a> technique is used to compare the similarity between the layer representations, before and after training on the second task.</p>
      </li>
      <li>
        <p>Higher layer representations change significantly when training over two tasks while the lower layer representations remain stable.</p>
      </li>
      <li>
        <p>When finetuning on the second task, freezing the lower layers has only a minor effect on the accuracy of the second task.</p>
      </li>
      <li>
        <p>In <em>layer reset</em> experiments, after training on the second task, the weights of some of the layers are reset to their values after training on the first task.</p>

        <ul>
          <li>Resetting the weights of higher layers leads to significant improvement in the performance on the first task.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>Do common approaches for countering catastrophic forgetting work by stabilizing the higher layers?</p>

    <ul>
      <li>
        <p>Yes - both <a href="https://arxiv.org/abs/1612.00796">EWC</a> and replay-based approaches counter catastrophic forgetting work by stabilizing the higher layers.</p>
      </li>
      <li>
        <p>This is demonstrated by showing that as the quadratic penalty for EWC (or fraction of data from replay buffer) increases (to reduce catastrophic forgetting), the representations for higher layers change less during the second task.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>When training over a sequence of tasks, are similar tasks more likely to be forgotten than different tasks?</p>

    <ul>
      <li>
        <p>Setup I</p>

        <ul>
          <li>
            <p>Training over a sequence of two binary classification tasks.</p>
          </li>
          <li>
            <p>Task 1: Two related classes (say <code class="language-plaintext highlighter-rouge">ship</code> and <code class="language-plaintext highlighter-rouge">truck</code>)</p>
          </li>
          <li>
            <p>Task 2: Two related classes, which may or may not be related to the classes for Task 1. For example, the classes could be</p>

            <ul>
              <li>
                <p><code class="language-plaintext highlighter-rouge">cat</code> and <code class="language-plaintext highlighter-rouge">horse</code> (not related to classes of the first task)</p>
              </li>
              <li>
                <p><code class="language-plaintext highlighter-rouge">plane</code> and <code class="language-plaintext highlighter-rouge">car</code> (related to the classes of the first task)</p>
              </li>
            </ul>
          </li>
          <li>
            <p>Training over semantically similar tasks (here <code class="language-plaintext highlighter-rouge">plane</code> and <code class="language-plaintext highlighter-rouge">car</code>) leads to less forgetting.</p>
          </li>
        </ul>
      </li>
      <li>
        <p>Setup II</p>

        <ul>
          <li>
            <p>Training over a sequence of two classification tasks.</p>
          </li>
          <li>
            <p>Task 1: Four classes where the classes can be grouped into two groups (say <code class="language-plaintext highlighter-rouge">deer</code>, <code class="language-plaintext highlighter-rouge">dog</code>, <code class="language-plaintext highlighter-rouge">ship</code> and <code class="language-plaintext highlighter-rouge">truck</code>)</p>
          </li>
          <li>
            <p>Task 2: Two related classes, which may be related to group 1 or group 2. For example, the classes could be two animals or two objects.</p>
          </li>
          <li>
            <p>After training on the second task, classes (from Task 1), which are in the different group as classes from Task 2, are forgotten less.</p>
          </li>
        </ul>
      </li>
      <li>
        <p>Conclusion</p>

        <ul>
          <li>
            <p>Task representational similarity is a function of both underlying data and optimization procedure.</p>
          </li>
          <li>
            <p>Forgetting is most severe for task representations of intermediate similarity.</p>
          </li>
          <li>
            <p>Representational similarity is necessary but not a sufficient condition for forgetting.</p>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>How does catastrophic forgetting change as the task similarity changes?</p>

    <ul>
      <li>
        <p>If the model learns different representations for dissimilar tasks, increasing dissimilarity can help to avoid forgetting.</p>
      </li>
      <li>
        <p>When training the two-task, two-class (per task) CIFAR-10 setup with an “others” class (classes not already used in the setup), the forgetting is reduced.</p>
      </li>
    </ul>
  </li>
</ul>

</div>

<div class="related">
  <h2>Related Posts</h2>
  <ul class="related-posts">
    
      <li>
        <h3>
          <a href="https://shagunsodhani.com/papers-I-read/Toolformer-Language-Models-Can-Teach-Themselves-to-Use-Tools">
            Toolformer - Language Models Can Teach Themselves to Use Tools
            <small>10 Feb 2023</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="https://shagunsodhani.com/papers-I-read/Synthesized-Policies-for-Transfer-and-Adaptation-across-Tasks-and-Environments">
            Synthesized Policies for Transfer and Adaptation across Tasks and Environments
            <small>29 Mar 2021</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="https://shagunsodhani.com/papers-I-read/Deep-Neural-Networks-for-YouTube-Recommendations">
            Deep Neural Networks for YouTube Recommendations
            <small>22 Mar 2021</small>
          </a>
        </h3>
      </li>
    
  </ul>
</div>
      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    
<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/

var disqus_config = function () {
this.page.url = "https://shagunsodhani.com/papers-I-read/Anatomy-of-Catastrophic-Forgetting-Hidden-Representations-and-Task-Semantics"  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = "/Anatomy-of-Catastrophic-Forgetting-Hidden-Representations-and-Task-Semantics"; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://papers-i-read.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>


    <script>
      (function(document) {
        var toggle = document.querySelector('.sidebar-toggle');
        var sidebar = document.querySelector('#sidebar');
        var checkbox = document.querySelector('#sidebar-checkbox');

        document.addEventListener('click', function(e) {
          var target = e.target;

          if(!checkbox.checked ||
             sidebar.contains(target) ||
             (target === checkbox || target === toggle)) return;

          checkbox.checked = false;
        }, false);
      })(document);
    </script>

  </body>
</html>
