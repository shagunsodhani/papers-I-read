<!DOCTYPE html>
<html lang="en-us">
  
  <script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    processEscapes: true
  }
});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      HyperNetworks &middot; Papers I Read
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="https://shagunsodhani.com/papers-I-read/public/css/poole.css">
  <link rel="stylesheet" href="https://shagunsodhani.com/papers-I-read/public/css/syntax.css">
  <link rel="stylesheet" href="https://shagunsodhani.com/papers-I-read/public/css/lanyon.css">
  <link rel="stylesheet" href="https://shagunsodhani.com/papers-I-read/public/css/style.css">
  <link rel="stylesheet" href="https://shagunsodhani.com/papers-I-read/public/font-awesome-4.7.0/css/font-awesome.css">

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://shagunsodhani.com/papers-I-read/public/apple-touch-icon-precomposed.png">
  <link rel="shortcut icon" href="https://shagunsodhani.com/papers-I-read/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>

  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-68140113-4"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-68140113-4');
</script>


  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <p>I am trying a new initiative - <i>A Paper A Week</i>. This blog will hold all the notes and summaries.</p>
  </div>

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item" href="https://shagunsodhani.com/papers-I-read/">Home</a>

    

    
    
      
        
      
    
      
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://shagunsodhani.com/papers-I-read/archieve">Archive</a>
        
      
    
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://shagunsodhani.com/papers-I-read/tags">Tags</a>
        
      
    

    <!-- <a class="sidebar-nav-item" href="https://github.com/shagunsodhani/papers-I-read/archive/v1.0.0.zip">Download</a> -->
    <a class="sidebar-nav-item" href="https://github.com/shagunsodhani/papers-I-read">GitHub project</a>
    <a class="sidebar-nav-item" href="https://shagunsodhani.com/papers-I-read/atom.xml">Feed</a>
    <!-- <span class="sidebar-nav-item">Currently v1.0.0</span> -->
  </nav>

  <div class="sidebar-item">
    <p>
      &copy; 2024. All rights reserved.
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="https://shagunsodhani.com/papers-I-read/" title="Home">Papers I Read</a>
            <small>Notes and Summaries</small>
          </h3>
        </div>
      </div>

      <div class="container content">
        <div class="post">
  <h1 class="post-title">HyperNetworks</h1>
  <p class="entry-tags"><a href="https://shagunsodhani.com/papers-I-read/tags.html#2016" title="Pages tagged 2016" rel="tag">2016</a> &bull; <a href="https://shagunsodhani.com/papers-I-read/tags.html#ICLR+2017" title="Pages tagged ICLR 2017" rel="tag">ICLR 2017</a> &bull; <a href="https://shagunsodhani.com/papers-I-read/tags.html#AI" title="Pages tagged AI" rel="tag">AI</a> &bull; <a href="https://shagunsodhani.com/papers-I-read/tags.html#HyperNetwork" title="Pages tagged HyperNetwork" rel="tag">HyperNetwork</a> &bull; <a href="https://shagunsodhani.com/papers-I-read/tags.html#ICLR" title="Pages tagged ICLR" rel="tag">ICLR</a></p>
  <span class="post-date">25 Jan 2021</span>
  <h2 id="introduction">Introduction</h2>

<ul>
  <li>
    <p>The paper explores HyperNetworks. The idea is to use one network (HyperNetwork) to generate the weights for another network.</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1609.09106">Link to the paper</a></p>
  </li>
  <li>
    <p><a href="https://github.com/hardmaru/supercell/blob/master/supercell.py">Author’s implementation</a></p>
  </li>
</ul>

<h2 id="approach">Approach</h2>

<h3 id="static-hypernetworks---hypernetworks-for-cnns">Static HyperNetworks - HyperNetworks for CNNs</h3>

<ul>
  <li>
    <p>Consider a $D$ layer CNN where the parameters for the $j^{th}$ layer are stored in a matrix $K^j$ of the shape $N_{in}f_{size} \times N_{out}f_{size}$.</p>
  </li>
  <li>
    <p>The HyperNetwork is implemented as a two-layer linear network where the input is a layer embedding $z^j$, and the output is $K^j$.</p>
  </li>
  <li>
    <p>The first layer (of the HyperNetwork) maps the input to $N_{in}$ different outputs using $N_{in}$ weight matrices.</p>
  </li>
  <li>
    <p>The second layer maps the different $N_{in}$ inputs to $K_{i}$ using a shared matrix. The resulting $N_{in}$ (number of) $K_{i}$ matrices are concatenated to obtain $K^j$.</p>
  </li>
  <li>
    <p>As a side note, HyperNetworks have much fewer params than the network for which it produces weights.</p>
  </li>
  <li>
    <p>In a general case, the kernel dimensions (across layers) are not of the same size but integer multiples of some basic sizes. In that case, the HyperNetwork can generate kernels for the basic size, which can be concatenated to form larger kernels. This would require additional input embeddings but not require a change in the architecture of HyperNetwork.</p>
  </li>
</ul>

<h3 id="dynamic-hypernetworks---hypernetworks-for-rnns">Dynamic HyperNetworks - HyperNetworks for RNNs</h3>

<ul>
  <li>
    <p>HyperRNNs/HyperLSTMs denote HyperNetworks that generates weights for RNNs/LSTMs.</p>
  </li>
  <li>
    <p>HyperRNNs implement a form of relaxed weight sharing - an alternative to the full weight sharing of the traditional RNNs.</p>
  </li>
  <li>
    <p>At any timestamp $t$, the input to the HyperRNN is the concatenated vector $x_{t}$ (input to the RNN at time $t$) and the hidden state $h_{t-1}$ of the RNN. The output is the weight for the main RNN at timestep $t$.</p>
  </li>
  <li>
    <p>In practice, a <em>weight scaling vector</em> $d$ is used to reduce the memory footprint, which would otherwise be $dim$ times the memory of a standard RNN. $dim$ is the dimensionality of the embedding vector $z_j$.</p>
  </li>
</ul>

<h2 id="experiments">Experiments</h2>

<ul>
  <li>
    <p>HyperNetworks are used to train standard CNNs for MNIST and ResNets for CIFAR 10. In these experiments, HyperNetworks slightly underperform the best performing models but uses much fewer parameters.</p>
  </li>
  <li>
    <p>HyperLSTMs trained on the Penn Treebank dataset and Hutter Prize Wikipedia dataset outperform the stacked LSTMs and perform similar to layer-norm LSTMs. Interestingly, using HyperLSTMs with layer-norm improves performance over HyperLSTMs.</p>
  </li>
  <li>
    <p>Given the similar performance of HyperLSTMs and layer-norm LSTMs, the paper conducted an ablation study to understand if HyperLSTMs learned a weight adjustment policy similar to the statistics-based approach used by layer-norm LSTMs.</p>

    <ul>
      <li>However, the analysis of the histogram of the hidden states suggests that using layer-norm reduces the saturation effect while in HyperLSTMs, the cell is saturated most of the time. This indicates that the two models are learning different policies.</li>
    </ul>
  </li>
  <li>
    <p>HyperLSTMs are also evaluated for handwriting sequence generation by training in the IAM online handwriting dataset.</p>

    <ul>
      <li>While HyperLSTMs are quite effective on this task, combining them with layer-norm degrades the performance.</li>
    </ul>
  </li>
  <li>
    <p>On the WMT’14 En-to-Fr machine translation task, HyperLSTMs outperform LSTM based approaches.</p>
  </li>
</ul>

</div>

<div class="related">
  <h2>Related Posts</h2>
  <ul class="related-posts">
    
      <li>
        <h3>
          <a href="https://shagunsodhani.com/papers-I-read/Toolformer-Language-Models-Can-Teach-Themselves-to-Use-Tools">
            Toolformer - Language Models Can Teach Themselves to Use Tools
            <small>10 Feb 2023</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="https://shagunsodhani.com/papers-I-read/Synthesized-Policies-for-Transfer-and-Adaptation-across-Tasks-and-Environments">
            Synthesized Policies for Transfer and Adaptation across Tasks and Environments
            <small>29 Mar 2021</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="https://shagunsodhani.com/papers-I-read/Deep-Neural-Networks-for-YouTube-Recommendations">
            Deep Neural Networks for YouTube Recommendations
            <small>22 Mar 2021</small>
          </a>
        </h3>
      </li>
    
  </ul>
</div>
      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    
<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/

var disqus_config = function () {
this.page.url = "https://shagunsodhani.com/papers-I-read/HyperNetworks"  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = "/HyperNetworks"; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://papers-i-read.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>


    <script>
      (function(document) {
        var toggle = document.querySelector('.sidebar-toggle');
        var sidebar = document.querySelector('#sidebar');
        var checkbox = document.querySelector('#sidebar-checkbox');

        document.addEventListener('click', function(e) {
          var target = e.target;

          if(!checkbox.checked ||
             sidebar.contains(target) ||
             (target === checkbox || target === toggle)) return;

          checkbox.checked = false;
        }, false);
      })(document);
    </script>

  </body>
</html>
