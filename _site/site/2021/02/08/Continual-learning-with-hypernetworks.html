<h2 id="introduction">Introduction</h2>

<ul>
  <li>
    <p>The paper proposes the use of task-conditioned <a href="https://shagunsodhani.com/papers-I-read/HyperNetworks">HyperNetworks</a> for lifelong learning / continual learning setups.</p>
  </li>
  <li>
    <p>The idea is, the HyperNetwork would only need to remember the task-conditioned weights and not the input-output mapping for all the data points.</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1906.00695">Link to the paper</a></p>
  </li>
  <li>
    <p><a href="https://github.com/chrhenning/hypercl">Author’s Implementation</a></p>
  </li>
</ul>

<h2 id="terminology">Terminology</h2>

<ul>
  <li>
    <p>$f$ denotes the network for the given $t^{th}$ task.</p>
  </li>
  <li>
    <p>$h$ denotes the HyperNetwork that generates the weights for $f$.</p>
  </li>
  <li>
    <p>$\Theta_{h}$ denotes the parameters of $h$.</p>
  </li>
  <li>
    <p>$e^{t}$ denotes the input task-embedding for the $t^{th}$ task.</p>
  </li>
</ul>

<h2 id="approach">Approach</h2>

<ul>
  <li>
    <p>When training on the $t^{th}$ task, the HyperNetworks generates the weights for the network $f$.</p>
  </li>
  <li>
    <p>The current task loss is computed using the generated weights, and the candidate weight update ($\Delta \Theta_{h}$) is computed for $h$.</p>
  </li>
  <li>
    <p>The actual parameter change is computed by the following expression:</p>
  </li>
</ul>

<p>$L_{total} = L{task}(\Theta_{h}, e^{T}, X^{T}, Y^{T}) + \frac{\beta_{output}}{T-1} \sum_{t=1}^{T-1} | f_{h}(e^{t}, \Theta_{h}^*) - f_{h}(e^{(t)}, \Theta_{h} + \Delta \Theta_{h} ))|^2$</p>

<ul>
  <li>
    <p>$L_{task}$ is the loss for the current task.</p>
  </li>
  <li>
    <p>$(X^{T}, Y^{T})$ denotes the training datapoints for the $T^{th}$ task.</p>
  </li>
  <li>
    <p>$\beta_{output}$ is a hyperparameter to control the regularizer’s strength.</p>
  </li>
  <li>
    <p>$\Theta_{h}^*$ denotes the optimal parameters after training on the $T-1$ tasks.</p>
  </li>
  <li>
    <p>$\Theta_{h} + \Delta \Theta_{h}$ denotes the one-step update on the current $h$ model.</p>
  </li>
  <li>
    <p>In practice, the task encoding $e^{t}$ is chunked into smaller vectors, and these vectors are fed as input to the HyperNetwork.</p>
  </li>
  <li>
    <p>This enables the HyperNetwork to produce weights iteratively, instead of all at once, thus helping to scale to larger models.</p>
  </li>
  <li>
    <p>The paper also considers the problem of inferring the task embedding from a given input pattern.</p>
  </li>
  <li>
    <p>Specifically, the paper uses task-dependent uncertainty, where the task embedding with the least predictive uncertainty is chosen as the task embedding for the given unknown task. This approach is referred to as HNET+ENT.</p>
  </li>
  <li>
    <p>The paper also considers using HyperNetworks to learn the weights for a task-specific generative model. This generative model will be used to generate pseudo samples for rehearsal-based approaches. The paper considers two cases:</p>

    <ul>
      <li>
        <p>HNET+R where the replay model (i.e., the generative model) is parameterized using a HyperNetwork.</p>
      </li>
      <li>
        <p>HNET+TIR, where an auxiliary task inference classifier is used to predict the task identity.</p>
      </li>
    </ul>
  </li>
</ul>

<h2 id="experiments">Experiments</h2>

<ul>
  <li>
    <p>Three setups are considered</p>

    <ul>
      <li>
        <p>CL1 - Task identity is given to the model.</p>
      </li>
      <li>
        <p>CL2 - Task identity is not given, but task-specific heads are used.</p>
      </li>
      <li>
        <p>CL3 - Task identity needs to be explicitly inferred.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>On the permuted MNIST task, the proposed approach outperforms baselines like Synaptic Intelligence and Online EWC, and the performance gap is more significant for larger task sequences.</p>
  </li>
  <li>
    <p>Forward knowledge transfer is observed with the CIFAR datasets.</p>
  </li>
  <li>
    <p>One potential limitation (which is more of a limitation of HyperNetworks) is that HyperNetworks may be harder to scale for larger models like ResNet50 or transformers, thus limiting their usefulness for lifelong learning use cases.</p>
  </li>
</ul>
