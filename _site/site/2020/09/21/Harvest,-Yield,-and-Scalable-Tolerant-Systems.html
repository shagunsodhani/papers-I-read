<h2 id="introduction">Introduction</h2>

<ul>
  <li>
    <p>A classic paper that looks into strategies for scaling large systems that can tolerate graceful degradation.</p>
  </li>
  <li>
    <p><a href="https://dl.acm.org/doi/10.5555/822076.822436">Link to the paper</a></p>
  </li>
</ul>

<h2 id="cap-theorem">CAP Theorem</h2>

<ul>
  <li>
    <p>CAP refers to strong <strong>C</strong>onsistency, high <strong>A</strong>vailability, and <strong>P</strong>artitionability.</p>
  </li>
  <li>
    <p>Strong consistency refers to single copy ACID consistency.</p>
  </li>
  <li>
    <p>High availability means any consumer can access the data anytime. Generally, this is achieved by adding one or more data replicas.</p>
  </li>
  <li>
    <p>Partitionability means that the system can survive a partition between the different replicas.</p>
  </li>
  <li>
    <p>Strong CAP theorem states that any system can have only two out of three properties.</p>
  </li>
  <li>
    <p>Weak CAP theorem says that stronger are the guarantees about any two properties, weaker are the third propertyâ€™s guarantees.</p>
  </li>
</ul>

<h2 id="harvest-yield-and-cap-theorem">Harvest, Yield, and CAP Theorem</h2>

<ul>
  <li>
    <p>Assume that the clients are making a request to a server.</p>
  </li>
  <li>
    <p>There are two quantities of interest here:</p>

    <ul>
      <li>Yield - the probability of completing a request.</li>
      <li>Harvest - completeness of answer to a query.</li>
    </ul>
  </li>
  <li>
    <p>In the presence of faults, a tradeoff can is made between yield and harvest. This tradeoff applies to both read and update queries.</p>
  </li>
</ul>

<h2 id="two-strategies-for-scaling-systems">Two strategies for scaling systems</h2>

<h3 id="trading-harvest-for-yield">Trading Harvest for Yield</h3>

<ul>
  <li>
    <p>In a hundred node cluster (without replication), a single-node failure reduces harvest by 1 %, and in the case of multi-node failure, the harvest degrades linearly.</p>
  </li>
  <li>
    <p>The probability of losing high-priority data can be reduced by replicating it. However, replicating all the data would not n guarantee 100% harvest and yield despite significant costs.</p>
  </li>
</ul>

<h3 id="application-decomposition-and-orthogonal-mechanisms">Application Decomposition and Orthogonal Mechanisms</h3>

<ul>
  <li>
    <p>Decompose a large application into subcomponents so that each component can be provisioned separately. Strong consistency can only be applied only on the components that need it, instead of the application as a whole.</p>
  </li>
  <li>
    <p>Further, failure of one or more components need not cause the application to fail as a whole.</p>
  </li>
  <li>
    <p>Decomposition also provides the opportunity to use orthogonal mechanisms, i.e., mechanisms independent of other mechanisms with no runtime interface.</p>
  </li>
  <li>
    <p>Composition of orthogonal subsystems improves the robustness of runtime interactions by <em>locally</em> containing the errors. For example, the orthogonal components can be restarted /replaced independently without affecting other running components.</p>
  </li>
</ul>
