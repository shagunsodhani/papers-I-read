<!DOCTYPE html>
<html lang="en-us">
  
  <script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    processEscapes: true
  }
});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Massively Multilingual Neural Machine Translation in the Wild - Findings and Challenges &middot; Papers I Read
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="https://shagunsodhani.github.io/papers-I-read/public/css/poole.css">
  <link rel="stylesheet" href="https://shagunsodhani.github.io/papers-I-read/public/css/syntax.css">
  <link rel="stylesheet" href="https://shagunsodhani.github.io/papers-I-read/public/css/lanyon.css">
  <link rel="stylesheet" href="https://shagunsodhani.github.io/papers-I-read/public/css/style.css">
  <link rel="stylesheet" href="https://shagunsodhani.github.io/papers-I-read/public/font-awesome-4.7.0/css/font-awesome.css">

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://shagunsodhani.github.io/papers-I-read/public/apple-touch-icon-precomposed.png">
  <link rel="shortcut icon" href="https://shagunsodhani.github.io/papers-I-read/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>

  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-68140113-4"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-68140113-4');
</script>


  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <p>I am trying a new initiative - <i>A Paper A Week</i>. This blog will hold all the notes and summaries.</p>
  </div>

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item" href="https://shagunsodhani.github.io/papers-I-read/">Home</a>

    

    
    
      
        
      
    
      
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://shagunsodhani.github.io/papers-I-read/archieve">Archive</a>
        
      
    
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
          <a class="sidebar-nav-item" href="https://shagunsodhani.github.io/papers-I-read/tags">Tags</a>
        
      
    

    <!-- <a class="sidebar-nav-item" href="https://github.com/shagunsodhani/papers-I-read/archive/v1.0.0.zip">Download</a> -->
    <a class="sidebar-nav-item" href="https://github.com/shagunsodhani/papers-I-read">GitHub project</a>
    <a class="sidebar-nav-item" href="https://shagunsodhani.github.io/papers-I-read/atom.xml">Feed</a>
    <!-- <span class="sidebar-nav-item">Currently v1.0.0</span> -->
  </nav>

  <div class="sidebar-item">
    <p>
      &copy; 2021. All rights reserved.
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="https://shagunsodhani.github.io/papers-I-read/" title="Home">Papers I Read</a>
            <small>Notes and Summaries</small>
          </h3>
        </div>
      </div>

      <div class="container content">
        <div class="post">
  <h1 class="post-title">Massively Multilingual Neural Machine Translation in the Wild - Findings and Challenges</h1>
  <p class="entry-tags"><a href="https://shagunsodhani.github.io/papers-I-read/tags.html#2019" title="Pages tagged 2019" rel="tag">2019</a> &bull; <a href="https://shagunsodhani.github.io/papers-I-read/tags.html#Multi+Domain" title="Pages tagged Multi Domain" rel="tag">Multi Domain</a> &bull; <a href="https://shagunsodhani.github.io/papers-I-read/tags.html#Multi+Task" title="Pages tagged Multi Task" rel="tag">Multi Task</a> &bull; <a href="https://shagunsodhani.github.io/papers-I-read/tags.html#Natural+Language+Processing" title="Pages tagged Natural Language Processing" rel="tag">Natural Language Processing</a> &bull; <a href="https://shagunsodhani.github.io/papers-I-read/tags.html#Neural+Machine+Translation" title="Pages tagged Neural Machine Translation" rel="tag">Neural Machine Translation</a> &bull; <a href="https://shagunsodhani.github.io/papers-I-read/tags.html#AI" title="Pages tagged AI" rel="tag">AI</a> &bull; <a href="https://shagunsodhani.github.io/papers-I-read/tags.html#NLP" title="Pages tagged NLP" rel="tag">NLP</a> &bull; <a href="https://shagunsodhani.github.io/papers-I-read/tags.html#NMT" title="Pages tagged NMT" rel="tag">NMT</a> &bull; <a href="https://shagunsodhani.github.io/papers-I-read/tags.html#Scale" title="Pages tagged Scale" rel="tag">Scale</a></p>
  <span class="post-date">30 Jan 2020</span>
  <h2 id="introduction">Introduction</h2>

<ul>
  <li>
    <p>The paper proposes to build a universal neural machine translation system that can translate between any pair of languages.</p>
  </li>
  <li>
    <p>As a concrete instance, the paper prototypes a system that handles 103 languages (25 Billion translation pairs).</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1907.05019">Link to the paper</a></p>
  </li>
</ul>

<h2 id="why-universal-machine-translation">Why universal Machine Translation</h2>

<ul>
  <li>
    <p>Hypothesis: <em>The learning signal from one language should benefit the quality of other languages</em><a href="https://link.springer.com/article/10.1023/A:1007379606734">1</a></p>
  </li>
  <li>
    <p>This positive transfer is evident for low resource languages but tends to hurt the performance for high resource languages.</p>
  </li>
  <li>
    <p>In practice, adding new languages reduces the effective per-task capacity of the model.</p>
  </li>
</ul>

<h2 id="desiderata-for-multilingual-translation-model">Desiderata for Multilingual Translation Model</h2>

<ul>
  <li>
    <p>Maximize the number of languages within one model.</p>
  </li>
  <li>
    <p>Maximize the positive transfer to low resource languages.</p>
  </li>
  <li>
    <p>Minimize the negative interference to high resource languages.</p>
  </li>
  <li>
    <p>Perform well ion the realistic, multi-domain settings.</p>
  </li>
</ul>

<h2 id="datasets">Datasets</h2>

<ul>
  <li>
    <p>In-house corpus generated by crawling and extracting parallel sentences from the web.</p>
  </li>
  <li>
    <p>102 languages, with 25 billion sentence pairs.</p>
  </li>
  <li>
    <p>Compared with the existing datasets, this dataset is much larger, spans more domains, has a good variation in the amount of data available for different language pairs, and is noisier. These factors bring additional challenges to the universal NMT setup.</p>
  </li>
</ul>

<h2 id="baselines">Baselines</h2>

<ul>
  <li>
    <p>Dedicated Bilingual models (variants of Transformers).</p>
  </li>
  <li>
    <p>Most bilingual experiments used Transformer big and a shared source-target sentence-piece model (SPE).</p>
  </li>
  <li>
    <p>For medium and low resource languages, the Transformer Base was also considered.</p>
  </li>
  <li>
    <p>Batch size of 1 M tokes per-batch. Increasing the batch size improves model quality and speeds up convergence.</p>
  </li>
</ul>

<h2 id="effect-of-transfer-and-interference">Effect of Transfer and Interference</h2>

<ul>
  <li>
    <p>The paper compares the following two setups with the baseline:</p>

    <ul>
      <li>
        <p>Combine all the datasets and train over them as if it is a single dataset.</p>
      </li>
      <li>
        <p>Combine all the datasets but upsample low resource languages so all that all the languages are equally likely to appear in the combined dataset.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>A target “index” is prepended with every input sentence to indicate which language it should be translated into.</p>
  </li>
  <li>
    <p>Shared encoder and decoder are used across all the language pairs.</p>
  </li>
  <li>
    <p>The two setups use a batch size of 4M tokens.</p>
  </li>
</ul>

<h3 id="results">Results</h3>

<ul>
  <li>
    <p>When all the languages are equally sampled, the performance on the low resource languages increases, at the cost of performance on high resource languages.</p>
  </li>
  <li>
    <p>Training over all the data at once reverse this trend.</p>
  </li>
</ul>

<h3 id="countering-interference">Countering Interference</h3>

<ul>
  <li>
    <p>Temperature based sampling strategy is used to control the ratio of samples from different language pairs.</p>
  </li>
  <li>
    <p>A balanced sampling strategy improves the performance for the high resource languages (though not as good as the multilingual baselines) while retaining the high transfer performance on the low resource languages.</p>
  </li>
  <li>
    <p>Another reason behind the lagging performance (as compared to bilingual baselines) is the capacity of the multilingual models.</p>
  </li>
  <li>
    <p>Some open problems to consider:</p>

    <ul>
      <li>
        <p>Task Scheduling - How to decide the order in which different language pairs should be trained.</p>
      </li>
      <li>
        <p>Optimization for multitask learning - How to design optimizer, loss functions, etc. that can exploit task similarity.</p>
      </li>
      <li>
        <p>Understanding Transfer:</p>

        <ul>
          <li>
            <p>For the low resource languages, translating multiple languages to English leads to improved performance than translating English to multiple languages.</p>
          </li>
          <li>
            <p>This can be explained as follows: In the first case (many-to-one), the setup is that of a multi-domain model (each source language is a domain). In the second case (one-to-many), the setup is that of multitasking.</p>
          </li>
          <li>
            <p>NMT models seem to be more amenable to transfer across multiple domains than transfer across tasks (since the decoder distribution does not change much).</p>
          </li>
          <li>
            <p>In terms of zero-shot performance, the performance for most language pairs increases as the number of languages change from 10 to 102.</p>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="effect-of-preprocessing-and-vocabulary">Effect of preprocessing and vocabulary</h2>

<ul>
  <li>
    <p>Sentence Piece Model (SPM) is used.</p>
  </li>
  <li>
    <p>Temperature sampling is used to sample vocabulary from different languages.</p>
  </li>
  <li>
    <p>Using smaller vocabulary (and hence smaller sub-word tokens) perform better for low resource languages, probably due to improved generalization.</p>
  </li>
  <li>
    <p>Low and medium resource languages tend to perform better with higher temperatures.</p>
  </li>
</ul>

<h2 id="effect-of-capacity">Effect of Capacity</h2>

<ul>
  <li>Using deeper models improves performance (as compared to the wider models with the same number of parameters) on most language pairs.</li>
</ul>

</div>

<div class="related">
  <h2>Related Posts</h2>
  <ul class="related-posts">
    
      <li>
        <h3>
          <a href="https://shagunsodhani.github.io/papers-I-read/Energy-based-Models-for-Continual-Learning">
            Energy-based Models for Continual Learning
            <small>18 Jan 2021</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="https://shagunsodhani.github.io/papers-I-read/GPipe-Easy-Scaling-with-Micro-Batch-Pipeline-Parallelism">
            GPipe - Easy Scaling with Micro-Batch Pipeline Parallelism
            <small>11 Jan 2021</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="https://shagunsodhani.github.io/papers-I-read/Compositional-Explanations-of-Neurons">
            Compositional Explanations of Neurons
            <small>04 Jan 2021</small>
          </a>
        </h3>
      </li>
    
  </ul>
</div>
      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    
<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/

var disqus_config = function () {
this.page.url = "https://shagunsodhani.github.io/papers-I-read/Massively-Multilingual-Neural-Machine-Translation-in-the-Wild-Findings-and-Challenges"  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = "/Massively-Multilingual-Neural-Machine-Translation-in-the-Wild-Findings-and-Challenges"; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://papers-i-read.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>


    <script>
      (function(document) {
        var toggle = document.querySelector('.sidebar-toggle');
        var sidebar = document.querySelector('#sidebar');
        var checkbox = document.querySelector('#sidebar-checkbox');

        document.addEventListener('click', function(e) {
          var target = e.target;

          if(!checkbox.checked ||
             sidebar.contains(target) ||
             (target === checkbox || target === toggle)) return;

          checkbox.checked = false;
        }, false);
      })(document);
    </script>

  </body>
</html>
